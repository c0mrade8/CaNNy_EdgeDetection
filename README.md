# ðŸ“¸ Edge Detection App (Software Engineering Intern â€“ R&D Assignment)

This project implements a **real-time edge detection pipeline** using **OpenCV**, **OpenGL ES**, and **Camera2 API** on Android, with a companion **TypeScript web viewer** for visualization.

---

## ðŸ§± Project Main Structure

/app/src/main
â”œâ”€â”€/java/com/example/edgedetectionapp/  
â”œâ”€â”€ MainActivity.kt â†’ Android entry point; handles camera feed, edge toggle, and FPS counter  
â”œâ”€â”€ CameraHelper.kt â†’ Camera2 API helper for capturing YUV frames  
â”œâ”€â”€ ImageUtils.kt â†’ Converts YUV_420_888 frames to RGBA (OpenCV Mat)  
â”œâ”€â”€ GLRenderer.kt â†’ OpenGL ES 2.0 renderer displaying processed frames  
â”‚ â””â”€â”€ -- this is the expected /gl file   
â””â”€â”€ cpp/  
â”œâ”€â”€ native-lib.cpp â†’ C++ code for OpenCV edge detection (Canny), native C++ implementation file that runs image processing logic using OpenCV via the JNI bridge (Java â†” C++)  
â”‚ â””â”€â”€ -- this is the expected /jni file  
â”œâ”€â”€ CMakeLists.txt â†’ tells CMake (the native build system) how to compile native-lib.cpp and link it with OpenCV and Androidâ€™s NDK    
â”‚ â””â”€â”€ -- this is the expected /jni file  
â””â”€â”€ res/  
â”œâ”€â”€ layout/activity_main.xml â†’ UI layout with GLSurfaceView, FPS counter, and toggle button  
â”œâ”€â”€ values/strings.xml â†’ App text resources  
â”œâ”€â”€ values/colors.xml â†’ Color definitions 
â””â”€â”€ AndroidManifest.xml â†’ declares everything the Android system needs to know before running the app  
â””â”€â”€ README.md  
â””â”€â”€ build.gradle.kts â†’ defines Android SDK versions, Dependencies (OpenCV, AppCompat, etc.), Build types (debug/release), Native CMake configuration  
â””â”€â”€ settings.gradle.kts â†’ tells Gradle which modules belong to the project  

/web  
â”œâ”€â”€ index.html â†’ Static web page showing a sample processed frame  
â”œâ”€â”€ viewer.ts â†’ TypeScript script updating FPS/resolution overlay  
â”œâ”€â”€ viewer.js â†’ Compiled JavaScript output from viewer.ts  
â”œâ”€â”€ styles.css â†’ Styling for the web viewer  
â””â”€â”€ sample.png â†’ Saved processed frame from the Android app  


>  **Note:**  
> The `/app`, `/jni`, `/gl`, and `/web` structure is represented conceptually.  
> Android Studio enforces its own `src/main/java` and `res` folder structure â€” this README maps those to the logical modules defined in the assignment.

---

## âš™ï¸ Features

âœ… **Real-time camera processing** using Androidâ€™s `Camera2` API  
âœ… **Edge detection** via OpenCVâ€™s `Canny` operator in C++ (JNI)  
âœ… **OpenGL ES rendering** for efficient frame display  
âœ… **Toggle button** to switch between *Live Feed* and *Edge Detection*  
âœ… **FPS overlay** for real-time performance monitoring  
âœ… **TypeScript + Web viewer** displaying a static sample with simulated FPS  

---

## ðŸ§© Technical Overview

### ðŸ”¹ Android App
- Written in **Kotlin**
- Uses **OpenCV (JNI)** for native image processing
- Camera frames (YUV_420_888) are converted to RGBA using OpenCV
- OpenGL ES 2.0 displays frames efficiently via a `GLSurfaceView`
- `native-lib.cpp` performs:
  ```cpp
  cvtColor(input, output, COLOR_RGBA2GRAY);
  GaussianBlur(output, output, Size(5, 5), 1.5);
  Canny(output, output, 100, 200);
  cvtColor(output, output, COLOR_GRAY2RGBA);
  ```

- Also included, Live FPS counter updates dynamically on-screen

## Web Viewer

A minimal static TypeScript + HTML page that:
- Displays a saved processed frame (sample.png)
- Simulates FPS/resolution updates via DOM manipulation
- Demonstrates familiarity with modern TypeScript tooling

## How It Works

- Camera2 captures YUV frames â†’ delivered via ImageReader.
- ImageUtils.imageToRgba() converts them into OpenCV Mat (RGBA).
- When â€œShow Edgesâ€ is pressed:
  -> JNI function processFrame() applies Canny edge detection.
- Result is sent to OpenGL renderer for display.
- FPS is measured and shown live on-screen.
- The processed frame can be exported for the /web viewer.

# Setup & Build Instructions
# Android App

## Requirements
- Android Studio (Giraffe or later) (used Narwhal 3 version 1.3.7)
- OpenCV Android SDK 4.x+ (used 4.12.0)
- Minimum SDK: 24 (Android 7.0)

## Steps
- Open the project in Android Studio.
- Sync Gradle to download dependencies.
- Connect an Android device. (via USB cable)
- Enable the developer mode on the android device and tick all necessary permissions(like install app through usb)
- Run the app.

## Permissions
- Camera permission is requested at runtime.
- Also, enable file transfer.

# Web Viewer

## Requirements
- Node.js + npm

## Steps
- Navigate to the web/ folder:
```bash
cd web
```
- Compile TypeScript to JavaScript:

```bash
npx tsc viewer.ts --target ES6 --outFile viewer.js
```
- Open index.html in your browser.

# Output
## Live Feed: Grayscale camera preview
## Edge Detection: Canny edge output (white edges on black background)
## Web Viewer:	Displays saved frame + simulated FPS overlay

# Technologies Used
- Kotlin, C++, TypeScript, HTML, CSS, Camera2, GLSurfaceView, JNI, OpenCV-Android 4.12.0, OpenGL ES 2.0.

> * Note*
> The Android project uses the default app/src/main/java and res layout enforced by Android Studio.
> The logical structure is as follows:
> /app â†’ Kotlin + Android logic
> /jni â†’ C++ OpenCV native processing
> /gl â†’ OpenGL rendering code
> /web â†’ TypeScript viewer

## Author
Niharika Rampathi  
Email ID: niharikarampathi2704@gmail.com  
Alternative Email ID: 22bds050@iiitdwd.ac.in  
